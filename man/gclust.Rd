% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gclust.R
\name{gclust}
\alias{gclust}
\alias{gclust.default}
\alias{gclust.dist}
\title{The Genie++ Hierarchical Clustering Algorithm}
\usage{
gclust(d, ...)

\method{gclust}{default}(
  d,
  gini_threshold = 0.3,
  M = 1L,
  postprocess = c("boundary", "none", "all"),
  distance = c("euclidean", "l2", "manhattan", "cityblock", "l1", "cosine"),
  cast_float32 = TRUE,
  verbose = FALSE,
  ...
)

\method{gclust}{dist}(
  d,
  gini_threshold = 0.3,
  M = 1L,
  postprocess = c("boundary", "none", "all"),
  verbose = FALSE,
  ...
)
}
\arguments{
\item{d}{either a numeric matrix (or an object coercible to one,
e.g., a data frame with numeric-like columns) or an
object of class \code{dist}, see \code{\link[stats]{dist}}.}

\item{...}{further arguments passed to or from other methods.}

\item{gini_threshold}{threshold for the Genie correction, i.e.,
the Gini index of the cluster size distribution;
Threshold of 1.0 disables the correction.
Low thresholds highly penalise the formation of small clusters.}

\item{M}{smoothing factor; M=1 gives the original Genie algorithm.}

\item{postprocess}{one of "boundary" (default), "none", "all";
in effect only if M>1. By default, only "boundary" points are merged
with their nearest "core" points. To force a classical
n_clusters-partition of a data set (with no notion of noise),
choose "all".}

\item{distance}{metric used to compute the linkage, one of:
"euclidean" (synonym: "l2"),
"manhattan" (a.k.a. "l1" and "cityblock"), "cosine"}

\item{cast_float32}{logical; whether to compute the distances using 32-bit
instead of 64-bit precision floating-point arithmetic (up to 2x faster)}

\item{verbose}{logical; whether to print diagnostic messages
and progress information}
}
\value{
A list of class \code{hclust}, see \code{\link[stats]{hclust}}.
}
\description{
TODO
}
\details{
Note that as with all the distance-based methods, standardisation
of the input features is definitely worth giving a try.
}
\examples{
library("datasets")
data("iris")
X <- iris[1:4]
#h <- gclust(X)
# y_pred <- cutree(h, 3)
y_test <- iris[,5]
#plot(iris[,2], iris[,3], col=y_pred,
#   pch=as.integer(iris[,5]), asp=1, las=1)
#adjusted_rand_score(y_test, y_pred)

}
\references{
Gagolewski M., Bartoszuk M., Cena A.,
Genie: A new, fast, and outlier-resistant hierarchical clustering algorithm,
\emph{Information Sciences} 363, 2016, pp. 8-23.
}
